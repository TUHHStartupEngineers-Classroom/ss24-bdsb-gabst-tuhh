[
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "# Task 1\nFor task 1, we load, wrangle and visualize the data wrt. to revenue by state.\n\n1 Loading of libraries\n\nsuppressWarnings({\n  library(\"readxl\")\n  library(\"magrittr\")\n  library(\"tidyverse\")\n  library(lubridate)\n})\n\n\n2 Loading and joining of data\nData is stored in content/data, so we have to change the working directory for loading of data. Then we read the data in and join it.\n\nsuppressWarnings({\n  setwd(\"..\")\n})\n\nbikes_tbl &lt;- read_excel(\"./data/01_bike_sales/01_raw_data/bikes.xlsx\")\norder_lines&lt;-read_excel(\"./data/01_bike_sales/01_raw_data/orderlines.xlsx\")\n\n#&gt; New names:\n#&gt; • `` -&gt; `...1`\n\nbikeshops_tbl  &lt;- read_excel(\"./data/01_bike_sales/01_raw_data/bikeshops.xlsx\")\n# joining\nbikes_orderlines_bikeshops &lt;-order_lines %&gt;%\n  left_join(bikes_tbl, by=c(\"product.id\" = \"bike.id\")) %&gt;%\n  left_join(bikeshops_tbl, by=c(\"customer.id\" = \"bikeshop.id\"))\n\nbikes_orderlines_bikeshops %&gt;% glimpse()\n\n#&gt; Rows: 15,644\n#&gt; Columns: 19\n#&gt; $ ...1           &lt;chr&gt; \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\"…\n#&gt; $ order.id       &lt;dbl&gt; 1, 1, 2, 2, 3, 3, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7…\n#&gt; $ order.line     &lt;dbl&gt; 1, 2, 1, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1…\n#&gt; $ order.date     &lt;dttm&gt; 2015-01-07, 2015-01-07, 2015-01-10, 2015-01-10, 2015-0…\n#&gt; $ customer.id    &lt;dbl&gt; 2, 2, 10, 10, 6, 6, 6, 6, 6, 22, 8, 8, 8, 8, 16, 16, 16…\n#&gt; $ product.id     &lt;dbl&gt; 2681, 2411, 2629, 2137, 2367, 1973, 2422, 2655, 2247, 2…\n#&gt; $ quantity       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1…\n#&gt; $ model          &lt;chr&gt; \"Spectral CF 7 WMN\", \"Ultimate CF SLX Disc 8.0 ETAP\", \"…\n#&gt; $ model.year     &lt;dbl&gt; 2021, 2020, 2021, 2019, 2020, 2020, 2020, 2021, 2020, 2…\n#&gt; $ frame.material &lt;chr&gt; \"carbon\", \"carbon\", \"carbon\", \"carbon\", \"aluminium\", \"c…\n#&gt; $ weight         &lt;dbl&gt; 13.80, 7.44, 14.06, 8.80, 11.50, 8.80, 8.20, 8.85, 14.4…\n#&gt; $ price          &lt;dbl&gt; 3119, 5359, 2729, 1749, 1219, 1359, 2529, 1559, 3899, 6…\n#&gt; $ category       &lt;chr&gt; \"Mountain - Trail - Spectral\", \"Road - Race - Ultimate\"…\n#&gt; $ gender         &lt;chr&gt; \"female\", \"unisex\", \"unisex\", \"unisex\", \"unisex\", \"unis…\n#&gt; $ url            &lt;chr&gt; \"https://www.canyon.com/en-de/mountain-bikes/trail-bike…\n#&gt; $ name           &lt;chr&gt; \"AlexandeRad\", \"AlexandeRad\", \"WITT-RAD\", \"WITT-RAD\", \"…\n#&gt; $ location       &lt;chr&gt; \"Hamburg, Hamburg\", \"Hamburg, Hamburg\", \"Bremen, Bremen…\n#&gt; $ lat            &lt;dbl&gt; 53.57532, 53.57532, 53.07379, 53.07379, 48.78234, 48.78…\n#&gt; $ lng            &lt;dbl&gt; 10.015340, 10.015340, 8.826754, 8.826754, 9.180819, 9.1…\n\n\n\n3 Wrangling\nWe reuse total price logic for easy plotting and separate location into city and state.\n\nbikes_orderlines_bikeshops&lt;-bikes_orderlines_bikeshops %&gt;%  \n  mutate(total.price = price * quantity) %&gt;%\n  separate(col    = location,\n           into   = c(\"city\", \"state\"),\n           sep    = \", \") \n\n\n4 Grouping/Manipulation\nWe group the data by state and sum up the total price. Then we reuse the sales_text for nicer plotting.\n\nsales_by_location&lt;- bikes_orderlines_bikeshops[, c(\"state\", \"city\", \"total.price\")] %&gt;%\n  group_by(state) %&gt;%\n  summarize(sales=sum(total.price)) %&gt;%\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\nsales_by_location\n\n\n\n  \n\n\n\n\n5 Visualization\nWe visualize the sales data by state. By inspection we find out, that NRW has the most revenue from bike sales.\n\nsales_by_location %&gt;%\n  # color by category_1\n  ggplot(aes(x = state, y = sales, fill=state)) +\n  geom_bar(stat = \"identity\") +  # bar plot\n  geom_label(aes(label = sales_text), position = position_stack(vjust = 0.95), size=2.5\n  ) + # adding labels to the bars\n\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))+ # changing direction of labels\n  labs(title = \"Revenue and state\",\n       subtitle = \"North Rhine-Westphalia has most revenue, then Bremen, followed by Bavaria.\", x = \"State\", y = \"Revenue\", fill = \"State\") # legend, title and subtitle\n\n\n\n\n\n\n\n# Task 2\nFor task 2, we load, wrangle and visualize the data wrt. revenue by state and year. Loading and wrangling are not necessary, as we can reuse our results from before.\n\n6 Grouping\nThis time we group by location and year.\n\nsuppressWarnings({\n  sales_by_location_and_year&lt;-bikes_orderlines_bikeshops[, c(\"order.date\", \"state\", \"city\", \"total.price\")]\n  sales_by_location_and_year_grouped&lt;- sales_by_location_and_year %&gt;%\n  mutate(order.date = year(order.date)) %&gt;%\n  group_by(order.date, state) %&gt;%\n  summarize(sales=sum(total.price)) %&gt;%\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n})\n\n#&gt; `summarise()` has grouped output by 'order.date'. You can override using the\n#&gt; `.groups` argument.\n\nsales_by_location_and_year\n\n\n\n  \n\n\n\n\n7 Visualization\nWe do two plots, once a facet plot and once a stacked bar plot, as the latter visualizes the proportions quite nicely, while the former helps understand the individual trend.\nFirst the facet plot:\n\nsales_by_location_and_year_grouped %&gt;%\n  # color by category_1\n  ggplot(aes(x = order.date, y = sales, fill = state)) +\n  # stack\n  geom_bar(stat = \"identity\") +\n  geom_label(aes(label = sales_text), position = position_stack(vjust = 0.5), size=2.5\n  ) + # Adding labels to the bars\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~state) +  # Facet by state\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(title = \"Revenue by year and state\",\n       subtitle = \"Some states have an upwards trend, some stagnate and few have a slight downward trend.\", x = \"Year\", y = \"Revenue\", fill = \"State\")\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nStacked bar plot:\n\nsales_by_location_and_year_grouped %&gt;%\n  # color by category_1\n  ggplot(aes(x = order.date, y = sales, fill = state)) +\n  # stack\n  geom_bar(stat = \"identity\") +\n  geom_label(aes(label = sales_text), position = position_stack(vjust = 0.5), size=2.5\n  ) + # Adding labels to the bars\n\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(title = \"Revenue by year and state as stacked bar plot.\", x = \"Year\", y = \"Revenue\", fill = \"State\")"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#task-1",
    "href": "content/01_journal/01_tidyverse.html#task-1",
    "title": "Tidyverse",
    "section": "\n1 Task 1",
    "text": "1 Task 1\nFor task 1, we load, wrangle and visualize the data wrt. to revenue by state.\nLoading of libraries\n\nlibrary(\"readxl\")\n\n#&gt; Warning: package 'readxl' was built under R version 4.2.3\n\nlibrary(\"magrittr\")\n\n#&gt; Warning: package 'magrittr' was built under R version 4.2.3\n\nlibrary(\"tidyverse\")\n\n#&gt; Warning: package 'tidyverse' was built under R version 4.2.3\n\n\n#&gt; Warning: package 'ggplot2' was built under R version 4.2.3\n\n\n#&gt; Warning: package 'tibble' was built under R version 4.2.3\n\n\n#&gt; Warning: package 'tidyr' was built under R version 4.2.3\n\n\n#&gt; Warning: package 'readr' was built under R version 4.2.3\n\n\n#&gt; Warning: package 'purrr' was built under R version 4.2.3\n\n\n#&gt; Warning: package 'dplyr' was built under R version 4.2.3\n\n\n#&gt; Warning: package 'stringr' was built under R version 4.2.3\n\n\n#&gt; Warning: package 'forcats' was built under R version 4.2.3\n\n\n#&gt; Warning: package 'lubridate' was built under R version 4.2.3\n\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.5\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ tidyr::extract()   masks magrittr::extract()\n#&gt; ✖ dplyr::filter()    masks stats::filter()\n#&gt; ✖ dplyr::lag()       masks stats::lag()\n#&gt; ✖ purrr::set_names() masks magrittr::set_names()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\n\nLoading and joining of data\nData is stored in content/data, so we have to change the working directory for loading of data. Then we read the data in and join it.\n\nsetwd(\"..\")\nbikes_tbl &lt;- read_excel(\"./data/01_bike_sales/01_raw_data/bikes.xlsx\")\norder_lines&lt;-read_excel(\"./data/01_bike_sales/01_raw_data/orderlines.xlsx\")\n\n#&gt; New names:\n#&gt; • `` -&gt; `...1`\n\nbikeshops_tbl  &lt;- read_excel(\"./data/01_bike_sales/01_raw_data/bikeshops.xlsx\")\n# joining\nbikes_orderlines_bikeshops &lt;-order_lines %&gt;%\n  left_join(bikes_tbl, by=c(\"product.id\" = \"bike.id\")) %&gt;%\n  left_join(bikeshops_tbl, by=c(\"customer.id\" = \"bikeshop.id\"))\n\nbikes_orderlines_bikeshops %&gt;% glimpse()\n\n#&gt; Rows: 15,644\n#&gt; Columns: 19\n#&gt; $ ...1           &lt;chr&gt; \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\"…\n#&gt; $ order.id       &lt;dbl&gt; 1, 1, 2, 2, 3, 3, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7…\n#&gt; $ order.line     &lt;dbl&gt; 1, 2, 1, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1…\n#&gt; $ order.date     &lt;dttm&gt; 2015-01-07, 2015-01-07, 2015-01-10, 2015-01-10, 2015-0…\n#&gt; $ customer.id    &lt;dbl&gt; 2, 2, 10, 10, 6, 6, 6, 6, 6, 22, 8, 8, 8, 8, 16, 16, 16…\n#&gt; $ product.id     &lt;dbl&gt; 2681, 2411, 2629, 2137, 2367, 1973, 2422, 2655, 2247, 2…\n#&gt; $ quantity       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1…\n#&gt; $ model          &lt;chr&gt; \"Spectral CF 7 WMN\", \"Ultimate CF SLX Disc 8.0 ETAP\", \"…\n#&gt; $ model.year     &lt;dbl&gt; 2021, 2020, 2021, 2019, 2020, 2020, 2020, 2021, 2020, 2…\n#&gt; $ frame.material &lt;chr&gt; \"carbon\", \"carbon\", \"carbon\", \"carbon\", \"aluminium\", \"c…\n#&gt; $ weight         &lt;dbl&gt; 13.80, 7.44, 14.06, 8.80, 11.50, 8.80, 8.20, 8.85, 14.4…\n#&gt; $ price          &lt;dbl&gt; 3119, 5359, 2729, 1749, 1219, 1359, 2529, 1559, 3899, 6…\n#&gt; $ category       &lt;chr&gt; \"Mountain - Trail - Spectral\", \"Road - Race - Ultimate\"…\n#&gt; $ gender         &lt;chr&gt; \"female\", \"unisex\", \"unisex\", \"unisex\", \"unisex\", \"unis…\n#&gt; $ url            &lt;chr&gt; \"https://www.canyon.com/en-de/mountain-bikes/trail-bike…\n#&gt; $ name           &lt;chr&gt; \"AlexandeRad\", \"AlexandeRad\", \"WITT-RAD\", \"WITT-RAD\", \"…\n#&gt; $ location       &lt;chr&gt; \"Hamburg, Hamburg\", \"Hamburg, Hamburg\", \"Bremen, Bremen…\n#&gt; $ lat            &lt;dbl&gt; 53.57532, 53.57532, 53.07379, 53.07379, 48.78234, 48.78…\n#&gt; $ lng            &lt;dbl&gt; 10.015340, 10.015340, 8.826754, 8.826754, 9.180819, 9.1…\n\n\nWrangling\nWe reuse total price logic for easy plotting and separate location into city and state.\n\nbikes_orderlines_bikeshops&lt;-bikes_orderlines_bikeshops %&gt;%  \n  mutate(total.price = price * quantity) %&gt;%\n  separate(col    = location,\n           into   = c(\"city\", \"state\"),\n           sep    = \", \") \n\nGrouping/Manipulation\nWe group the data by state and sum up the total price. Then we reuse the sales_text for nicer plotting.\n\nsales_by_location&lt;- bikes_orderlines_bikeshops[, c(\"state\", \"city\", \"total.price\")] %&gt;%\n  group_by(state) %&gt;%\n  summarize(sales=sum(total.price)) %&gt;%\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\nsales_by_location\n\n\n\n  \n\n\n\nVisualization\nWe visualize the sales data by state. By inspection we find out, that NRW has the most revenue from bike sales.\n\nsales_by_location %&gt;%\n  # color by category_1\n  ggplot(aes(x = state, y = sales, fill=state)) +\n  geom_bar(stat = \"identity\") +  # bar plot\n  geom_label(aes(label = sales_text), position = position_stack(vjust = 0.95), size=2.5\n  ) + # adding labels to the bars\n\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))+ # changing direction of labels\n  labs(title = \"Revenue and state\",\n       subtitle = \"North Rhine-Westphalia has most revenue, then Bremen, followed by Bavaria.\", x = \"State\", y = \"Revenue\", fill = \"State\") # legend, title and subtitle"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#task-2",
    "href": "content/01_journal/01_tidyverse.html#task-2",
    "title": "Tidyverse",
    "section": "\n2 Task 2",
    "text": "2 Task 2\nFor task 2, we load, wrangle and visualize the data wrt. revenue by state and year. Loading and wrangling are not necessary, as we can reuse our results from before.\nGrouping\nThis time we group by location and year.\n\nsales_by_location_and_year&lt;-bikes_orderlines_bikeshops[, c(\"order.date\", \"state\", \"city\", \"total.price\")]\nsales_by_location_and_year_grouped&lt;- sales_by_location_and_year %&gt;%\n  mutate(order.date = year(order.date)) %&gt;%\n  group_by(order.date, state) %&gt;%\n  summarize(sales=sum(total.price)) %&gt;%\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\n#&gt; `summarise()` has grouped output by 'order.date'. You can override using the\n#&gt; `.groups` argument.\n\nsales_by_location_and_year\n\n\n\n  \n\n\n\nVisualization\nWe do two plots, once a facet plot and once a stacked bar plot, as the latter visualizes the proportions quite nicely, while the former helps understand the individual trend.\nFirst the facet plot:\n\nsales_by_location_and_year_grouped %&gt;%\n  # color by category_1\n  ggplot(aes(x = order.date, y = sales, fill = state)) +\n  # stack\n  geom_bar(stat = \"identity\") +\n  geom_label(aes(label = sales_text), position = position_stack(vjust = 0.5), size=2.5\n  ) + # Adding labels to the bars\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~state) +  # Facet by state\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(title = \"Revenue by year and state\",\n       subtitle = \"Some states have an upwards trend, some stagnate and few have a slight downward trend.\", x = \"Year\", y = \"Revenue\", fill = \"State\")\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nStacked bar plot:\n\nsales_by_location_and_year_grouped %&gt;%\n  # color by category_1\n  ggplot(aes(x = order.date, y = sales, fill = state)) +\n  # stack\n  geom_bar(stat = \"identity\") +\n  geom_label(aes(label = sales_text), position = position_stack(vjust = 0.5), size=2.5\n  ) + # Adding labels to the bars\n\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(title = \"Revenue by year and state as stacked bar plot.\", x = \"Year\", y = \"Revenue\", fill = \"State\")"
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "content/03_other/06_links.html#r-and-r-studio",
    "href": "content/03_other/06_links.html#r-and-r-studio",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual ."
  },
  {
    "objectID": "content/03_other/06_links.html#additional-r-resources",
    "href": "content/03_other/06_links.html#additional-r-resources",
    "title": "Links",
    "section": "",
    "text": "Google is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "1 Loading of libraries\n\nsuppressWarnings({\n  library(tidyverse)\n  library(scales)\n  library(glue)\n  })\n\n# Challenge 1\n\ncovid_data_tbl &lt;- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#&gt; Rows: 392459 Columns: 67\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr   (4): iso_code, continent, location, tests_units\n#&gt; dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#&gt; date  (1): date\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n2 Subsetting\n\n# some predicates\nger &lt;- covid_data_tbl$location == \"Germany\"\nuk &lt;- covid_data_tbl$location == \"United Kingdom\"\nfr &lt;- covid_data_tbl$location == \"France\"\nesp &lt;- covid_data_tbl$location == \"Spain\"\nus &lt;- covid_data_tbl$location == \"United States\"\ntime_limit &lt;- covid_data_tbl$date &lt;= date(\"2022-04-19\")\n\n# subsetting data\ncountry_data &lt;- covid_data_tbl[(ger | uk | fr | esp | us) & time_limit,]\n\n\n3 Function for format labeling of y-axis\n\nformat_labels &lt;- function(x) {\n  paste0(format(x / 1e6, scientific = FALSE), \"M\")\n}\n\n\n4 Getting last relevant us/fr cases as number and text.\n\nlast_us_cases &lt;- country_data[country_data$location == \"United States\",] |&gt; arrange(date) |&gt; tail(1)\nlast_us_cases &lt;- last_us_cases$total_cases\nsuppressWarnings({\n  last_us_cases_text &lt;- format(last_us_cases, big.mark = \".\")\n})\n\n\nlast_fr_cases &lt;- country_data[country_data$location == \"France\",] |&gt; arrange(date) |&gt; tail(1)\nlast_fr_cases &lt;- last_fr_cases$total_cases\nsuppressWarnings(\n  last_fr_cases_text &lt;- format(last_fr_cases, big.mark = \".\")\n)\n\n\n5 Plotting\n\nsuppressWarnings({\n  country_data |&gt; select(date, total_cases, location) |&gt; group_by(location) |&gt; # total cases by location wanted\n    ggplot(aes(date, total_cases, color = location)) + # plotting\n    geom_line() + # line plot\n    theme_minimal() + # minimal theme\n    scale_x_date(labels = date_format(\"%B '%y\"), date_breaks = \"1 month\") + # x axis to monthly \n    theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"bottom\") + # rotating x-axis text and fixing legend position\n    guides(color = guide_legend(ncol = 3)) + # fixing legend layout  \n    scale_y_continuous(labels = format_labels, breaks = seq(0, 800, by = 50) * 1e6) + # y axis to million (using above function)\n  \n    labs(x = \"\", y = \"Cumulative Cases\", title = \"Confirmed Covid cases in Europe and USA\", subtitle = \"As of 19-04-22\", color = \"Country\") + # labels\n    geom_text(aes(x= date(\"2022-04-19\"), y = last_us_cases, label = glue(\"{last_us_cases_text} (US)\"), color=\"black\"), color=\"black\", hjust=0.8) + # us - deaths\n      geom_text(aes(x= date(\"2022-04-19\"), y = last_fr_cases, label =glue(\"{last_fr_cases_text} (Fr)\"), color=\"black\"), color=\"black\", hjust=0.8, vjust=-0.2) + # fr - deaths (for reference)\n    scale_color_manual(values = rainbow(length(unique(country_data$location)))) # the \"non-default\" color map. Viridis looked even worse.\n})\n\n#&gt; Warning in geom_text(aes(x = date(\"2022-04-19\"), y = last_us_cases, label = glue(\"{last_us_cases_text} (US)\"), : All aesthetics have length 1, but the data has 4180 rows.\n#&gt; ℹ Did you mean to use `annotate()`?\n\n\n#&gt; Warning in geom_text(aes(x = date(\"2022-04-19\"), y = last_fr_cases, label = glue(\"{last_fr_cases_text} (Fr)\"), : All aesthetics have length 1, but the data has 4180 rows.\n#&gt; ℹ Did you mean to use `annotate()`?\n\n\n#&gt; Warning: Removed 84 rows containing missing values or values outside the scale range\n#&gt; (`geom_line()`).\n\n\n\n\n\n\n\n\n# Challenge 2\nPlotting death rate by country on a world map.\n\n6 Wrangling\n\n# getting borders \nworld &lt;- map_data(\"world\")\n# mutating covid data names \ncovid_data_tbl &lt;- covid_data_tbl |&gt;  mutate(location = case_when(\n\n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location\n\n  )) %&gt;%\n  distinct()\n\n# create death_by_pop column and take the value for the last recorded date in the dataset\nplot_data &lt;- covid_data_tbl |&gt; mutate(death_by_pop=total_deaths/population) |&gt; filter(date==date(\"2024-04-07\"))\n\n# this is a bit weird; merging/joining puts the \"by\" column first in the result. this breaks the geom_map functionality...\nmerged_data &lt;- merge(world, plot_data[c(\"location\", \"death_by_pop\")], by.x = \"region\", by.y= \"location\", all.x=TRUE)\n# hence i use merge to combine the data, but then just append a column to the original world data\nworld$death_by_pop &lt;- merged_data$death_by_pop\n\n\n7 Visualization\n\nggplot() +\n  geom_map(data = world, map = world,\n           aes(map_id = region, fill = death_by_pop),\n           color = \"black\") + # basic plot, fill defines based on what the countries are filled, color defines color of country outline\n  expand_limits(x = world$long, y = world$lat)  + # sets width for plot\n  theme_minimal() + # reduces/removes unwanted elements\n  scale_fill_gradient(low = \"red\", high = \"darkred\", na.value = \"darkgray\", labels = percent_format()) + # gradient for fill\n  labs(y= \"\", x=\"\", title=\"Confirmed COVID-19 deaths relative to size of population\", subtitle=\"Around 6.2 million confirmed deaths worldwide.\", fill=\"Mortality Rate\") + # labels\n  theme(axis.text.x = element_blank(), \n        axis.text.y = element_blank()) # theme_minimal would not remove the numbers on the axes, this does."
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "1 Task 1\nGetting some (50 observations) weather data from openweatherapi. A table is printed and a scatterplot if temperature vs latitude is presented.\n\nsuppressWarnings(\n  {\n    library(httr)\n    library(glue)\n    library(tidyverse)\n    library(rvest)\n    library(RSQLite)\n    library(DBI)\n    library(xopen) \n  }\n)\n\n\n2 Getting Data from API: openweathermap.org\n\n# loading api token from a local file\nsuppressWarnings({\n  token&lt;- read.delim(\"my_openweatherapi_token.txt\") |&gt; names()\n})\n# defining column names and tibble frame\ncols &lt;- c(\"lat\",\"lon\", \"city_name\", \"country\", \"weather_desc\", \"temperature_c\", \"wind_deg\")\n\ndata &lt;- tibble(\n  lat = double(),\n  lon = double(),\n  city_name = character(),\n  country = character(),\n  weather_desc = character(),\n  temperature_c = double(),\n  wind_deg = double()\n)\n\n# getting weather for 50 random places from earth\nfor (i in 1:50) {\n  lat &lt;- runif(1, min = -90, max = 90)\n  lon &lt;- runif(1, min = -180, max = 180)\n  # making the url for each lat/lon and token\n  url &lt;- glue(\"https://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={token}&units=metric\")\n  # actual call to api\n  response &lt;- GET(url)\n  # getting content from html\n  cnt &lt;- content(response)\n  \n  # and storing the data in the data frame\n  data &lt;- bind_rows(data, tibble(\n    lat = lat,\n    lon = lon,\n    city_name = cnt$city$name,\n    country = cnt$city$country,\n    weather_desc = cnt$list[[1]]$weather[[1]]$description,\n    temperature_c = cnt$list[[2]]$main$temp,\n    wind_deg = cnt$list[[2]]$wind$deg\n  ))\n}\n\n\n3 Sanity Check: API call worked?\n\ndata\n\n\n\n  \n\n\n\n\n4 Example Visualization\n\nggplot(data, aes(x = abs(lat), y = temperature_c)) + # taking abs lat because we are interested in distance from ecuator\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) + # to check for correlation\n  labs(x = \"Absolute Latitude\", y = \"Temperature (C)\",\n       title = \"Plot of Absolute Latitude vs Temperature\")\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n5 Task 2\nWe are going to scrape radon-bikes.de.\n\n6 Define a function to get all bike urls..\n\nget_bike_urls &lt;- function() {\n  url_home &lt;- \"https://www.radon-bikes.de\"\n\n  html_home &lt;- read_html(url_home)\n\n  # getting the links for the categories\n\n  bike_categories &lt;- html_home |&gt;  html_elements(css=\"li.has-dropdown.js-dropdown &gt; ul &gt; li &gt; div &gt; a\") |&gt; html_attr(\"href\") |&gt; \n  str_subset(pattern = \"wear\", negate = T) |&gt;\n  str_c(url_home, ... = _)\n  \n  bike_urls &lt;- list()\n  \n  for (url in bike_categories) {\n    bike_url &lt;- read_html(url) |&gt; html_elements(css=\"div.row.columns.serienSlider &gt; div.mod &gt; div.js-slider-container &gt; div &gt; div.o-slick-slider__slide-content &gt; div.row &gt; a.a-button\") |&gt; html_attr(\"href\") |&gt;   str_c(url_home, ... = _)\n    \n    bike_urls &lt;- append(bike_urls, bike_url)\n  }\n  return (bike_urls)\n}\n\n\n7 and a function to parse an individual bike:\n\nget_bike_data &lt;- function(url) {\n  bike_price &lt;- read_html(url) |&gt;\n  html_element(css = \"span.m-bikedetail__price--active\") |&gt;\n  html_text() |&gt;\n  parse_number() |&gt;\n  as.numeric()\n  \n  # check for reasonable prices\n  if (bike_price &lt; 0 || bike_price &gt; 10000) {\n    bike_price &lt;- NaN\n  }\n  \n  bike_model &lt;- read_html(url) |&gt; \n  html_elements(css = \"h1.a-heading.a-heading--medium\") |&gt; \n  html_text() |&gt; \n  str_squish() # Clean\n  \n  bike_data &lt;- tibble(url   = url,\n                      model = bike_model,\n                      price = bike_price)\n\n  return(bike_data)\n}\n\n\n8 Last, we scrape the entire website, store the results in a tibble table and\n\nurls &lt;- get_bike_urls()\n\nmy_data &lt;- tibble(\n  url = character(),\n  model = character(),\n  price = double()\n)\n\nfor (bike_url in urls) {\n  bike_data &lt;- get_bike_data(bike_url)\n  my_data &lt;- bind_rows(my_data, bike_data)\n}\n\nhead(my_data, 10)\n\n\n\n  \n\n\n\n\n9 Put the resulting table into a sqlite db.\n\n# want to store data in content/data\nsuppressWarnings({setwd(\"..\")})\n\n# connect to file\ncon&lt;-dbConnect(drv=SQLite(), dbname = \"data/radon_bikes.sqlite\")\n# create table\ncreate_table_query &lt;- \"\nCREATE TABLE IF NOT EXISTS radon_bikes (\n    url TEXT,\n    model TEXT,\n    price INTEGER\n);\n\"\n\ndbExecute(con, create_table_query)\n\n#&gt; [1] 0\n\n# use dbi to write tibble to database \n# we do not want to duplicate the entire db, hence do not execute this line of code\nif (FALSE) {\n  dbWriteTable(con, \"radon_bikes\", my_data, append = TRUE)\n}\n# check whether everything worked\nresult &lt;- dbGetQuery(con, \"SELECT * FROM radon_bikes\")\n# looks good\nglimpse(result)\n\n#&gt; Rows: 139\n#&gt; Columns: 3\n#&gt; $ url   &lt;chr&gt; \"https://www.radon-bikes.de/mountainbike/hardtail/jealous/jealou…\n#&gt; $ model &lt;chr&gt; \"JEALOUS 8.0\", \"JEALOUS 9.0\", \"JEALOUS 10.0 EA\", \"JEALOUS 8.0\", …\n#&gt; $ price &lt;dbl&gt; 2999, 3399, 5499, 2199, 2599, 3299, 4499, 999, 999, 999, 999, 11…"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "1 Loading of libraries\n\nsuppressWarnings({\nlibrary(tidyverse)\nlibrary(vroom)\nlibrary(glue)\n})\n\n\n2 Loading the data\n\ndata_folder &lt;- \"03_data/Patent_data_reduced/\"\n\ncol_types_patent &lt;- list(\n  id = col_character(),\n  date = col_date(\"%Y-%m-%d\"),\n  num_claims = col_double()\n)\n\ncol_types_patent_assignee &lt;- list(patent_id=col_character(),\n                                  assignee_id=col_character())\n\ncol_types_assignee &lt;- list(id=col_character(),\n                               type=col_character(),\n                               organization=col_character())\n\n\ncol_types_uspc &lt;- list(patent_id=col_character(),\n                       mainclass_id=col_character(),\n                       sequence=col_double())\n\npatent_tbl &lt;- vroom(\n            file       = glue(\"{data_folder}patent.tsv\"), \n            delim      = \"\\t\", \n            col_types  = col_types_patent,\n            na         = c(\"\", \"NA\", \"NULL\")\n        )\n\npatent_assignee_tbl &lt;- vroom(\n            file       = glue(\"{data_folder}patent_assignee.tsv\"), \n            delim      = \"\\t\", \n            col_types  = col_types_patent_assignee,\n            na         = c(\"\", \"NA\", \"NULL\")\n        )\n\nassignee_tbl &lt;- vroom(\n            file       = glue(\"{data_folder}assignee.tsv\"), \n            delim      = \"\\t\", \n            col_types  = col_types_assignee,\n            na         = c(\"\", \"NA\", \"NULL\")\n        )\n\nuspc_tbl &lt;- vroom(\n            file       = glue(\"{data_folder}uspc.tsv\"), \n            delim      = \"\\t\", \n            col_types  = col_types_uspc,\n            na         = c(\"\", \"NA\", \"NULL\")\n        )\n\n\n3 Top Ten US companies (patent-wise) 2014\n\npatent_tbl &lt;- patent_tbl |&gt; mutate(date=month(date)) |&gt; rename(patent_id=id)\n\nus_assignee_tbl &lt;- assignee_tbl[assignee_tbl$type == \"2\",] |&gt; rename(assignee_id = id)\n\nus_patent_assignee_tbl &lt;- patent_assignee_tbl |&gt;\n  inner_join(us_assignee_tbl, by=\"assignee_id\")\n\ngrouped_us_patent_assignee_tbl &lt;- us_patent_assignee_tbl |&gt;\n  group_by(assignee_id) |&gt;\n  summarise(num_patents=n()) |&gt;\n  arrange(desc(num_patents))\n\n\nten_us_companies_with_most_patents &lt;- inner_join(head(grouped_us_patent_assignee_tbl, 10), us_assignee_tbl, by=\"assignee_id\")[c(\"organization\", \"num_patents\")]\n\nten_us_companies_with_most_patents\n\n\n\n  \n\n\n\n\n4 Top Ten US companies (patent-wise) in August of 2014\n\npatent_tbl_august &lt;- patent_tbl[patent_tbl$date == 8,]\n\nten_us_companies_with_most_patents_august &lt;- us_patent_assignee_tbl |&gt;\n  inner_join(patent_tbl_august, by=\"patent_id\") |&gt;\n  group_by(organization) |&gt; \n  summarize(num_patents=n()) |&gt; # counts rows \n  arrange(desc(num_patents)) |&gt;\n  head(10)\n\nten_us_companies_with_most_patents_august\n\n\n\n  \n\n\n\n\n5 Five most common USPCs for the global Top Ten companies (patent-wise) of 2014\n\n# type 2 and 3 are companies\ncompany_assignee_tbl &lt;- assignee_tbl[assignee_tbl$type == \"2\" | assignee_tbl$type == \"3\",] |&gt; rename(assignee_id = id)\n\n# global top ten for patents\nglobal_top_ten_frame &lt;- company_assignee_tbl |&gt; \n  inner_join(patent_assignee_tbl, by=\"assignee_id\") |&gt; \n  group_by(assignee_id) |&gt; \n  summarize(num_patents=n()) |&gt; \n  arrange(desc(num_patents)) |&gt; \n  head(10)\n\n# mapping company to uspc\n\ncompany_patent_uspc_tbl &lt;- company_assignee_tbl |&gt; \n  inner_join(patent_assignee_tbl, join_by(assignee_id)) |&gt; \n  inner_join(uspc_tbl, by=\"patent_id\", relationship = \"many-to-many\")\n\n\n# for creation of final result frame\ncompany_uspc&lt;- tibble(\n  name = character(),\n  fst = character(),\n  snd = character(),\n  third =  character(),\n  fourth =  character(),\n  fifth =  character()\n)\n\n# for each company in the top ten, get the 5 most common USPCs\nfor (company in global_top_ten_frame$assignee_id) {\n  top_uspc_codes &lt;- company_patent_uspc_tbl[company_patent_uspc_tbl$assignee_id == company,] |&gt;\n    group_by(mainclass_id) |&gt; \n    summarize(count = n()) |&gt; \n    arrange(desc(count)) |&gt; \n    head(5)\n  \n  comp_name &lt;- head(company_assignee_tbl[company_assignee_tbl$assignee_id==company,], 1)$organization\n  cls &lt;- top_uspc_codes$mainclass_id\n\n  company_uspc &lt;- company_uspc |&gt; add_row(name=comp_name,\n                          fst=cls[1],\n                          snd = cls[2],\n                          third =  cls[3],\n                          fourth =  cls[4],\n                          fifth =  cls[5])\n}\n# Top Five USPCs for each of the global Top Ten Companies\ncompany_uspc\n\n\n\n  \n\n\n\n\n6 And the global Top Five tech sectors\n\ntop_uspc_codes &lt;- company_patent_uspc_tbl[company_patent_uspc_tbl$assignee_id %in% global_top_ten_frame$assignee_id,] |&gt;\n    group_by(mainclass_id) |&gt; \n    summarize(count = n()) |&gt; \n    arrange(desc(count)) |&gt; \n    head(5)\n\n#Globally most innovative tech sectors\ntop_uspc_codes$mainclass_id\n\n#&gt; [1] \"257\" \"455\" \"370\" \"348\" \"709\""
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "Welcome to my Business Data Science Basics Journal"
  }
]